{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWCgbUkDonkb"
   },
   "source": [
    "#### **1단계: 환경 설정 및 데이터/모델 준비**\n",
    "\n",
    "Colab 런타임은 **GPU**로 설정하는 것을 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 154291,
     "status": "ok",
     "timestamp": 1751616668789,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "0OysWLo9u9n9",
    "outputId": "962b3c17-8f22-41d2-c678-cd26b8a5e416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.162-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.5.1.17->torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading ultralytics-8.3.162-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensorflow, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorboard-2.19.0 tensorflow-2.19.0 ultralytics-8.3.162 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ultralytics tensorflow torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4151,
     "status": "ok",
     "timestamp": 1751540063323,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "AnpyogjMvEeL",
    "outputId": "c47b2501-fd4f-4cbc-a297-8adfe50cd1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 44.1/112.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11641,
     "status": "ok",
     "timestamp": 1751616684188,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "krC8r25jonkd",
    "outputId": "6142689e-a840-4a37-d3b5-f4601e402688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "훈련을 위한 최종 data.yaml 파일을 생성합니다...\n",
      ": /content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml\n",
      "--- final_helmet_data.yaml 내용 ---\n",
      "names:\n",
      "- helmet\n",
      "- no-helmet\n",
      "nc: 2\n",
      "test: /content/drive/MyDrive/hackerton/safe/HardHatDetector/test/images\n",
      "train: /content/drive/MyDrive/hackerton/safe/HardHatDetector/train/images\n",
      "val: /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/images\n",
      "\n",
      "---------------------------------\n",
      "훈련에 사용될 YAML 파일 생성 완료: /content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# 구글 드라이브 마운트\n",
    "# 학습 데이터 크기와 결과 유지를 위해 데이터셋을 구글 드라이브에 연결\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "# 3. 데이터셋 경로 및 YAML 경로 변수 설정\n",
    "# 이전에 다운로드하고 압축을 푼 데이터셋의 경로를 사용합니다.\n",
    "DATASET_PATH = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector\"\n",
    "YAML_PATH = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/data.yaml\" # 경로를 수정한 YAML 파일\n",
    "\n",
    "print(\"훈련을 위한 최종 data.yaml 파일을 생성합니다...\")\n",
    "\n",
    "# 우리가 원하는, 명확한 클래스 이름 리스트를 직접 정의합니다.\n",
    "# Roboflow에서 export한 데이터셋의 클래스 순서와 동일해야 합니다.\n",
    "# (예: Roboflow에서 0=helmet, 1=no-helmet 순서였다면 그대로 유지)\n",
    "class_names = ['helmet', 'no-helmet']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# 최종 사용할 YAML 데이터 구성\n",
    "custom_data_yaml = {\n",
    "    'train': os.path.abspath(os.path.join(DATASET_PATH, 'train/images')),\n",
    "    'val': os.path.abspath(os.path.join(DATASET_PATH, 'valid/images')),\n",
    "    'test': os.path.abspath(os.path.join(DATASET_PATH, 'test/images')),\n",
    "    'nc': num_classes,\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "# 최종 YAML 파일 경로\n",
    "CUSTOM_YAML_PATH = '/content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml'\n",
    "\n",
    "# 새로운 YAML 파일로 저장\n",
    "with open(CUSTOM_YAML_PATH, 'w') as f:\n",
    "    yaml.dump(custom_data_yaml, f)\n",
    "\n",
    "print(f\": {CUSTOM_YAML_PATH}\")\n",
    "print(\"--- final_helmet_data.yaml 내용 ---\")\n",
    "with open(CUSTOM_YAML_PATH, 'r') as f:\n",
    "    print(f.read())\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "print(f\"훈련에 사용될 YAML 파일 생성 완료: {CUSTOM_YAML_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzzxM6lFonke"
   },
   "source": [
    "#### **2단계: YOLO 모델 훈련**\n",
    "\n",
    "이제 준비된 YAML 파일을 사용하여 모델 훈련을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5614296,
     "status": "ok",
     "timestamp": 1751531719298,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "AdOibue_5-F2",
    "outputId": "5f063e09-bcb6-420c-8a38-8a56b8a06f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/hackerton/safe/HardHatDetector/ptModel/yolo11s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=helmet_detection_run_with_augmentation, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 100MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 360MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.6±0.2 ms, read: 0.1±0.0 MB/s, size: 52.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/train/labels.cache... 4600 images, 42 backgrounds, 0 corrupt: 100%|██████████| 4600/4600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3183, len(boxes) = 11306. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.4 ms, read: 0.0±0.0 MB/s, size: 41.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      4.02G      1.087      1.222      1.258         23        640: 100%|██████████| 288/288 [04:10<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.693      0.377      0.463      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      4.82G     0.9646     0.8538      1.176         29        640: 100%|██████████| 288/288 [01:42<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.633      0.725      0.661      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      4.83G     0.9384     0.7968      1.166         24        640: 100%|██████████| 288/288 [01:45<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.651       0.71      0.719       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      4.83G      0.872     0.7443      1.128         18        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.873      0.681       0.81      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      4.83G      0.856     0.7052      1.111         42        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.866      0.652      0.793      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      4.83G     0.8113     0.6563      1.096         41        640: 100%|██████████| 288/288 [01:45<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.761      0.691      0.744      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      4.86G     0.7727     0.6251      1.074         35        640: 100%|██████████| 288/288 [01:42<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.805      0.797      0.829      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50       4.9G     0.7334     0.5963      1.057         25        640: 100%|██████████| 288/288 [01:47<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69       0.85      0.754      0.853      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      4.91G     0.7207     0.5715      1.042         21        640: 100%|██████████| 288/288 [01:44<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.884      0.638      0.783      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      4.91G        0.7     0.5614      1.033         18        640: 100%|██████████| 288/288 [01:45<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.844      0.739      0.847       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      4.91G     0.6928     0.5501      1.026         13        640: 100%|██████████| 288/288 [01:49<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.807      0.909      0.904      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      4.91G     0.6724     0.5302       1.02         20        640: 100%|██████████| 288/288 [01:48<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.744      0.594      0.655      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      4.91G     0.6636     0.5139      1.011         12        640: 100%|██████████| 288/288 [01:46<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.851      0.667      0.717      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      4.91G     0.6432      0.509      1.001         36        640: 100%|██████████| 288/288 [01:45<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.849      0.696      0.782      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      4.91G     0.6399      0.496      1.004         38        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.906      0.739      0.832      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      4.91G     0.6297     0.4944     0.9944         19        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.867      0.853      0.851      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      4.91G     0.6168     0.4785     0.9965         13        640: 100%|██████████| 288/288 [01:45<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.915      0.797      0.827      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      4.91G     0.6055     0.4669     0.9815         16        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.861      0.681      0.792      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      4.91G     0.5945     0.4662     0.9777         24        640: 100%|██████████| 288/288 [01:43<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.883      0.877      0.906      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      4.91G     0.5913     0.4599     0.9739         24        640: 100%|██████████| 288/288 [01:48<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69       0.83      0.855      0.875      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      4.91G     0.5817     0.4499     0.9772         15        640: 100%|██████████| 288/288 [01:48<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.895      0.861      0.876      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      4.91G     0.5693     0.4456     0.9724         23        640: 100%|██████████| 288/288 [01:47<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.919      0.823      0.867       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      4.91G     0.5529     0.4261     0.9593         80        640: 100%|██████████| 288/288 [01:51<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.849       0.87      0.899      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      4.91G     0.5524      0.431     0.9578         38        640: 100%|██████████| 288/288 [01:46<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.909      0.797       0.88       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      4.91G     0.5503     0.4172     0.9584         21        640: 100%|██████████| 288/288 [01:48<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.922      0.768      0.889      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      4.91G     0.5318     0.4082     0.9528         15        640: 100%|██████████| 288/288 [01:46<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.963      0.812      0.888      0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      4.91G     0.5291     0.4117     0.9521         22        640: 100%|██████████| 288/288 [01:45<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.841       0.87      0.884      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      4.91G     0.5282     0.4047     0.9486         16        640: 100%|██████████| 288/288 [01:46<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.861      0.841      0.882      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      4.91G      0.513     0.3909     0.9422         22        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.847      0.882      0.878      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      4.91G     0.5015     0.3833     0.9336         21        640: 100%|██████████| 288/288 [01:47<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.912      0.913      0.906      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      4.91G     0.5004     0.3805     0.9334         16        640: 100%|██████████| 288/288 [01:47<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.916      0.787      0.879       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      4.91G     0.4916     0.3749     0.9332         15        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.812      0.841      0.856      0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      4.91G     0.4876     0.3741     0.9265         30        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.948      0.794      0.884      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      4.91G     0.4831     0.3662     0.9259         16        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.899      0.904      0.921      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      4.91G     0.4741     0.3615     0.9221         15        640: 100%|██████████| 288/288 [01:46<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.886      0.903      0.913      0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      4.91G     0.4693     0.3591     0.9239         17        640: 100%|██████████| 288/288 [01:44<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.912      0.855      0.926      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      4.91G     0.4567     0.3503     0.9193         16        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.873      0.893       0.92      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      4.91G      0.457     0.3463     0.9168         16        640: 100%|██████████| 288/288 [01:46<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.926      0.723      0.869      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      4.91G     0.4526     0.3439     0.9163         33        640: 100%|██████████| 288/288 [01:47<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.922      0.854       0.91      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      4.94G     0.4381     0.3335     0.9089         13        640: 100%|██████████| 288/288 [01:47<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.931      0.855      0.909      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      4.94G     0.3754     0.2793     0.8619         12        640: 100%|██████████| 288/288 [01:49<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.927      0.736      0.871      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      4.94G     0.3714     0.2734     0.8626         10        640: 100%|██████████| 288/288 [01:44<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.875      0.813        0.9      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      4.94G     0.3539     0.2602     0.8572         33        640: 100%|██████████| 288/288 [01:47<00:00,  2.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.852      0.834      0.907      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      4.94G     0.3579     0.2599     0.8546          8        640: 100%|██████████| 288/288 [01:44<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.855      0.853      0.895      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      4.94G     0.3524     0.2566     0.8534         19        640: 100%|██████████| 288/288 [01:49<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.861      0.855      0.905      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      4.94G     0.3407      0.251     0.8477         13        640: 100%|██████████| 288/288 [01:43<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.942      0.783      0.908      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      4.94G     0.3387     0.2422     0.8466          9        640: 100%|██████████| 288/288 [01:43<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.945      0.841      0.914      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      4.94G     0.3293      0.237      0.845         14        640: 100%|██████████| 288/288 [01:45<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.948      0.826      0.922      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      4.94G     0.3263     0.2372     0.8479         13        640: 100%|██████████| 288/288 [01:43<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.935      0.837      0.921      0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      4.94G     0.3213     0.2319     0.8436         14        640: 100%|██████████| 288/288 [01:47<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.953      0.826      0.922      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 1.535 hours.\n",
      "Optimizer stripped from /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/last.pt, 19.2MB\n",
      "Optimizer stripped from /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.pt, 19.2MB\n",
      "\n",
      "Validating /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.pt...\n",
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.954      0.826      0.922      0.813\n",
      "                helmet         37         69      0.954      0.826      0.922      0.813\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강과 세부 설정 적용\n",
    "model = YOLO('/content/drive/MyDrive/hackerton/safe/HardHatDetector/ptModel/yolo11s.pt')\n",
    "training_results = model.train(\n",
    "    data=CUSTOM_YAML_PATH,\n",
    "    epochs=50,\n",
    "    patience=10,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "\n",
    "    # ---  데이터 증강 옵션 ---\n",
    "    # hsv_h=0.015,  # 색상(H) 변화 범위 (기본값: 0.015)\n",
    "    # hsv_s=0.7,    # 채도(S) 변화 범위 (기본값: 0.7)\n",
    "    # hsv_v=0.4,    # 명도(V) 변화 범위 (기본값: 0.4)\n",
    "    # degrees=10.0, # 이미지 회전 각도 (기본값: 0.0) -> 약간의 회전 추가\n",
    "    # translate=0.1,# 이미지 좌우/상하 이동 (기본값: 0.1)\n",
    "    # scale=0.2,    # 이미지 확대/축소 (기본값: 0.5) -> 스케일 변화를 조금 줄여봄\n",
    "    # shear=5.0,    # 이미지 기울이기 (기본값: 0.0) -> 약간의 기울임 추가\n",
    "    # flipud=0.5,   # 상하 뒤집기 확률 (기본값: 0.0) -> 상하 반전 데이터 추가\n",
    "    fliplr=0.5,   # 좌우 뒤집기 확률 (기본값: 0.5)\n",
    "    mosaic=0.5,   # 모자이크 증강 (여러 이미지를 합침) 확률 (기본값: 1.0)\n",
    "    # mixup=0.0,    # MixUp 증강 (두 이미지를 섞음) 확률 (기본값: 0.0) -> 약간 추가\n",
    "    # ------------------------------------\n",
    "\n",
    "    project=\"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results\", # 결과 저장 경로\n",
    "    name=\"helmet_detection_run_with_augmentation\" # 새로운 실행 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFOEP_vo5IDf"
   },
   "source": [
    "* **`project`**: 훈련 결과가 저장될 구글 드라이브의 상위 폴더를 지정하여, 런타임이 종료되어도 결과가 보존되도록 합니다.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Wed5Ybzonkg"
   },
   "source": [
    "### **3단계: 성능 검증 (F1 Score, 정확도 등)**\n",
    "\n",
    "훈련이 완료되면, 가장 성능이 좋았던 모델(`best.pt`)을 검증 데이터셋으로 평가하여 객관적인 성능 지표를 얻습니다.\n",
    "\n",
    "  * **주요 지표**:\n",
    "      * **Precision (정밀도)**: 모델이 \"헬멧\"이라고 예측한 것 중, 진짜 헬멧의 비율.\n",
    "      * **Recall (재현율)**: 실제 모든 헬멧 중에서, 모델이 \"헬멧\"이라고 맞춘 비율.\n",
    "      * **mAP (mean Average Precision)**: 정밀도와 재현율을 종합적으로 고려한, 객체 탐지 모델의 표준 성능 평가 지표. (가장 중요)\n",
    "      * **F1 Score**: 정밀도와 재현율의 조화 평균.\n",
    "\n",
    "`val.py` 스크립트는 이 지표들을 자동으로 계산하고, **Precision-Recall(PR) 커브, F1-Score 커브** 등 다양한 그래프를 생성해줍니다. ROC 커브는 주로 이진 분류 문제에 사용되며, 객체 탐지에서는 PR 커브가 더 일반적으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6118,
     "status": "ok",
     "timestamp": 1751531738868,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "olzbgNwSonkg",
    "outputId": "5a66e9d9-ba0f-40a4-814b-4e4733d31180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 성능 모델 로드 중: /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.pt\n",
      "\n",
      "모델 검증을 시작합니다...\n",
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 24.7±16.0 MB/s, size: 44.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.953      0.826      0.922      0.814\n",
      "                helmet         37         69      0.953      0.826      0.922      0.814\n",
      "Speed: 3.4ms preprocess, 18.4ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "\n",
      "--- 최종 검증 결과 ---\n",
      "mAP50-95: 81.42%\n",
      "mAP50:    92.23%\n"
     ]
    }
   ],
   "source": [
    "project_name = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results\"\n",
    "run_name = \"helmet_detection_run_with_augmentation\"\n",
    "\n",
    "# 훈련된 모델 중 가장 좋은 모델의 가중치 경로\n",
    "best_model_path = f\"{project_name}/{run_name}/weights/best.pt\"\n",
    "\n",
    "# 훈련된 모델 중 가장 성능이 좋았던 모델을 로드합니다.\n",
    "print(f\"최고 성능 모델 로드 중: {best_model_path}\")\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# .val() 메소드를 호출하여 검증을 수행합니다.\n",
    "# 훈련 시 사용했던 data.yaml 파일의 경로를 data 인자에 전달할 수 있습니다.\n",
    "# 만약 훈련 직후라면, 모델이 데이터셋 정보를 기억하고 있어 data 인자를 생략해도 됩니다.\n",
    "print(\"\\n모델 검증을 시작합니다...\")\n",
    "metrics = model.val(data=CUSTOM_YAML_PATH, imgsz=640)\n",
    "\n",
    "# 검증 결과 확인\n",
    "# metrics 객체에 모든 성능 지표가 담겨 있습니다.\n",
    "print(\"\\n--- 최종 검증 결과 ---\")\n",
    "print(f\"mAP50-95: {metrics.box.map * 100:.2f}%\")\n",
    "print(f\"mAP50:    {metrics.box.map50 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn9iN6wb0jPU"
   },
   "source": [
    "--- 최종 검증 결과 ---   \n",
    "mAP50-95: 81.42%  \n",
    "mAP50:    92.23%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvjMOdIwonkg"
   },
   "source": [
    "> 실행이 완료되면, 터미널에 mAP 수치가 출력되고, `runs/val/exp` 와 같은 폴더에 `F1_curve.png`, `PR_curve.png`, `confusion_matrix.png` 등의 결과 이미지 파일이 저장됩니다.\n",
    "\n",
    "-----\n",
    "\n",
    "### **4단계: 기본 모델과 학습된 모델의 정확도 비교 시각화**\n",
    "\n",
    "\n",
    " **성능 지표 비교 시각화**:\n",
    "      * 아래 코드로 기본 모델과 학습된 모델의 성능을 막대그래프로 비교합니다.\n",
    "\n",
    "<!-- end list -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15038,
     "status": "ok",
     "timestamp": 1751531772291,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "L-hYyhjVonkh",
    "outputId": "7e248264-a2a8-4ede-a3b7-88ce8ec2e20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 기본 모델(Baseline) 성능 검증 ---\n",
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 19.7±12.2 MB/s, size: 52.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69     0.0219      0.203     0.0167     0.0113\n",
      "                person         37         69     0.0219      0.203     0.0167     0.0113\n",
      "Speed: 2.2ms preprocess, 19.2ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/baseline_validation\u001b[0m\n",
      "베이스라인 모델 mAP50-95: 1.13%\n",
      "\n",
      "--- 2. 훈련된 모델(Fine-tuned) 성능 검증 ---\n",
      "Ultralytics 8.3.161 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 32.2±9.1 MB/s, size: 59.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.953      0.826      0.922      0.814\n",
      "                helmet         37         69      0.953      0.826      0.922      0.814\n",
      "Speed: 24.6ms preprocess, 12.2ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/finetuned_validation\u001b[0m\n",
      "훈련된 모델 mAP50-95: 81.42%\n",
      "\n",
      "--- 성능 비교 시각화 ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 기본 yolov11s 모델과 훈련된 yolo 모델의 성능 비교\n",
    "\"\"\"\n",
    "print(\"--- 1, 기본 모델(Baseline) 성능 검증 ---\")\n",
    "try:\n",
    "    # (1-1) 검증에 사용할 기본 모델을 로드\n",
    "    baseline_model = YOLO('/content/drive/MyDrive/hackerton/safe/HardHatDetector/ptModel/yolo11s.pt')\n",
    "\n",
    "    # (1-2) .val() 메소드를 호출하여 검증을 수행하고, 결과를 metrics 객체로 받습니다.\n",
    "    baseline_metrics = baseline_model.val(\n",
    "        data=CUSTOM_YAML_PATH,\n",
    "        imgsz=640,\n",
    "        name='baseline_validation' # 결과 저장 폴더 이름 지정\n",
    "    )\n",
    "\n",
    "    # (1-3) 주요 성능 지표를 저장합니다.\n",
    "    baseline_map50_95 = baseline_metrics.box.map\n",
    "    print(f\"베이스라인 모델 mAP50-95: {baseline_map50_95 * 100:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"기본 모델 검증 중 오류 발생: {e}\")\n",
    "    baseline_map50_95 = 0.0 # 오류 발생 시 0으로 처리\n",
    "\n",
    "\n",
    "print(\"\\n--- 2. 훈련된 모델(Fine-tuned) 성능 검증 ---\")\n",
    "try:\n",
    "    # (2-1) 가장 성능이 좋았던, 직접 훈련시킨 모델을 로드합니다.\n",
    "    finetuned_model = YOLO(best_model_path)\n",
    "\n",
    "    # (2-2) 동일한 검증 데이터셋으로 성능을 평가합니다.\n",
    "    finetuned_metrics = finetuned_model.val(\n",
    "        data=CUSTOM_YAML_PATH,\n",
    "        imgsz=640,\n",
    "        name='finetuned_validation'\n",
    "    )\n",
    "\n",
    "    # (2-3) 주요 성능 지표를 저장합니다.\n",
    "    finetuned_map50_95 = finetuned_metrics.box.map\n",
    "    print(f\"훈련된 모델 mAP50-95: {finetuned_map50_95 * 100:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"훈련된 모델 검증 중 오류 발생: {e}\")\n",
    "    finetuned_map50_95 = 0.0\n",
    "\n",
    "\n",
    "# --- 3. 성능 비교 시각화 ---\n",
    "print(\"\\n--- 3. 성능 비교 시각화 ---\")\n",
    "\n",
    "models = ['Baseline (yolov11s)', 'Fine-tuned Model']\n",
    "maps = [baseline_map50_95, finetuned_map50_95]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(models, maps, color=['#ff9999', '#66b3ff'])\n",
    "plt.ylabel('mAP@.5:.95')\n",
    "plt.title('Baseline vs. Fine-tuned Model Performance')\n",
    "plt.ylim(0, 1.0)\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.4f}', va='bottom', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1751532245903,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "urTz6mBxc-GO",
    "outputId": "2943bc38-0596-469c-8f72-2b4905e68608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 2\n",
      "{0: 'helmet', 1: 'no-helmet'}\n"
     ]
    }
   ],
   "source": [
    "# 모델 특징 확인\n",
    "finetuned_model = YOLO(best_model_path)\n",
    "print(type(finetuned_model.names), len(finetuned_model.names))\n",
    "\n",
    "print(finetuned_model.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sl6Ja2WpJ_X"
   },
   "source": [
    "-----\n",
    "### **5단계: 훈련된 pt 모델을 tflite 파일로 변환하고, 성능을 비교합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 52923,
     "status": "ok",
     "timestamp": 1751617991110,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "apMmD1J6dYUl",
    "outputId": "c306f848-73cd-48f3-ee84-ce53e5c10516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료: /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.pt\n",
      "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0,<1.4.0'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.3s\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.11M/1.11M [00:00<00:00, 173MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 32.32file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.58...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.4s, saved as '/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.onnx' (36.3 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.0...\n",
      "Saved artifact at '/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 6, 8400), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  133937791918992: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937791918800: TensorSpec(shape=(3, 3, 3, 32), dtype=tf.float32, name=None)\n",
      "  133937791919376: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  133937791922832: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937791918416: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  133937791923600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937791923408: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937791923984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937791923792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937791922448: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937791926096: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
      "  133937791924176: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  133937791925328: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  133937791925712: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  133937791924560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937791924752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937791925904: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
      "  133937791924368: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782899536: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937782899920: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782899728: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782900496: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782900304: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782901072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782900880: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782901840: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
      "  133937782903184: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  133937782900688: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  133937782900112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782901264: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782901456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782903376: TensorSpec(shape=(1, 1, 192, 256), dtype=tf.float32, name=None)\n",
      "  133937782903568: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782902608: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937782902032: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937782902416: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782903760: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937782904144: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782904720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782904528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782905488: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  133937782906832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782907216: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937782907024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782903952: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937782906256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782907600: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937782907984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782908176: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937782904336: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  133937782906064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782905680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937782908368: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782907792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782904912: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782905104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782908752: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  133937782907408: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782909136: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937782908944: TensorSpec(shape=(3, 3, 256, 512), dtype=tf.float32, name=None)\n",
      "  133937782908560: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937782909328: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  133937782909712: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937782910288: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782910096: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782911056: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  133937782912400: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782912784: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782912592: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782909520: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782911824: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782913168: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782913360: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782911632: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937782909904: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  133937782913552: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782911248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937782914128: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937782913936: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782910480: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782910672: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937782914320: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  133937782912976: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937782913744: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  133937782914896: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937782914512: TensorSpec(shape=(1, 1, 1024, 512), dtype=tf.float32, name=None)\n",
      "  133937782914704: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937702175760: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  133937702174800: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937702175568: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  133937702174992: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937702175376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  133937702177872: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702181520: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937702179984: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702179408: TensorSpec(shape=(1, 1, 256, 512), dtype=tf.float32, name=None)\n",
      "  133937702179600: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937702179216: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  133937702179024: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702180176: TensorSpec(shape=(1, 1, 512, 512), dtype=tf.float32, name=None)\n",
      "  133937702177104: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937702180560: TensorSpec(shape=(1, 1, 768, 256), dtype=tf.float32, name=None)\n",
      "  133937702175952: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702181328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702180368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702181712: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  133937702183056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937702180944: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  133937702180752: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702178832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702181136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702183632: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  133937702183440: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702183248: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
      "  133937702184016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702183824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702182288: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702184784: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
      "  133937702186128: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  133937702182480: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  133937702184208: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937702181904: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702184400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702186320: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  133937702186512: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702185552: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937702184976: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937702185360: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702188240: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  133937702188432: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702189008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702189776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702190928: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  133937702189968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937702190736: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
      "  133937660085648: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702190160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937702190352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937660086608: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  133937660088336: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937660087184: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  133937660086800: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937660086416: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937660085840: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  133937660087952: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937660088912: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937660089680: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937660091984: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  133937660089488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660092560: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937660092176: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702177680: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937823409424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937823410192: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937791913040: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937791913616: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937660090832: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  133937791913808: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660090640: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937791913424: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  133937791914576: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937660090064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937660090256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  133937791914000: TensorSpec(shape=(1, 1, 768, 512), dtype=tf.float32, name=None)\n",
      "  133937791914384: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937660092752: TensorSpec(shape=(3, 3, 512, 1), dtype=tf.float32, name=None)\n",
      "  133937660087568: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
      "  133937702187472: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  133937791919184: TensorSpec(shape=(512,), dtype=tf.float32, name=None)\n",
      "  133937660085456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  133937702187088: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660092944: TensorSpec(shape=(1, 1, 512, 128), dtype=tf.float32, name=None)\n",
      "  133937660086032: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  133937702187856: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937660093328: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660086992: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702187280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660094864: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  133937791914768: TensorSpec(shape=(3, 3, 512, 64), dtype=tf.float32, name=None)\n",
      "  133937660089296: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  133937660087760: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  133937702189392: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  133937702186704: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  133937660093712: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937791914192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660088528: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660086224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937702188624: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702186896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660095248: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937660093520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937660089872: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937660087376: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937702190544: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  133937702187664: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937660094672: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660093136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660091216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937660088144: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937702189584: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  133937702188048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660095440: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  133937660094096: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937660092368: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  133937660089104: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937660084688: TensorSpec(shape=(1, 1, 128, 2), dtype=tf.float32, name=None)\n",
      "  133937702189200: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  133937660094288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660095632: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  133937660088720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660091408: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  133937702188816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  133937660085264: TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
      "  133937660096976: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660096208: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660097936: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  133937660097168: TensorSpec(shape=(1, 4, 8400), dtype=tf.float32, name=None)\n",
      "  133937660099280: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660100432: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660093904: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660099856: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660099472: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  133937660097744: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  133937660096592: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  133937660097552: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 51.0s, saved as '/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model' (90.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as '/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/best_float32.tflite' (36.2 MB)\n",
      "\n",
      "Export complete (52.8s)\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/best_float32.tflite imgsz=640  \n",
      "Validate:        yolo val task=detect model=/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/best_float32.tflite imgsz=640 data=/content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "✅ tflite 모델 변환 성공!\n",
      "저장된 경로: /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/best_float32.tflite\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 훈련된 모델을 TensorFlow Lite로 변환\n",
    "# pytorch->onnx->tflite 순으로 onnx 포멧을 거쳐 변환됨\n",
    "\"\"\"\n",
    "\n",
    "# pytorch->onnx 변환\n",
    "# --- 1. yolo 모델 경로 설정 ---\n",
    "project_name = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results\"\n",
    "run_name = \"helmet_detection_run_with_augmentation\"\n",
    "\n",
    "# 가장 성능이 좋았던 모델의 .pt 파일 경로\n",
    "best_model_path = f\"{project_name}/{run_name}/weights/best.pt\"\n",
    "\n",
    "try:\n",
    "    # --- 2. 모델 로드 및 onnx 변환 ---\n",
    "    # (2-1) 훈련된 .pt 모델 로드\n",
    "    best_model = YOLO(best_model_path)\n",
    "    print(f\"모델 로드 완료: {best_model_path}\")\n",
    "\n",
    "    # (2-2) onnx로 내보내기\n",
    "    tflite_path = best_model.export(\n",
    "        format='tflite',   # tflite 포맷으로 지정\n",
    "        int8=False,        # INT8(양자화) 대신 float32로 정확도 우선\n",
    "        simplify=True,      # 그래프 최적화\n",
    "        data=CUSTOM_YAML_PATH, # 데이터셋 경로\n",
    "        imgsz=640          # 훈련 시 사용했던 이미지 크기 명시\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ tflite 모델 변환 성공!\")\n",
    "    print(f\"저장된 경로: {tflite_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 모델 변환 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyvk-UuFjxIb"
   },
   "source": [
    "#### 위 방법으로 바로 변환이 실패하고, onnx파일만 생성되는 경우 아래 코드를 실행\n",
    "onnx → TFLite 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBIQEFPuiqIa"
   },
   "outputs": [],
   "source": [
    "!pip install -U onnx2tf\n",
    "\n",
    "# onnx -> tflite 변환\n",
    "# 2. 경로 정의\n",
    "input_onnx_path = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best.onnx\"\n",
    "output_tf_path = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/\"\n",
    "\n",
    "# 3. onnx2tf 변환 (배치 크기 고정, 채널 순서 유지)\n",
    "!onnx2tf -i {input_onnx_path} -o {output_tf_path} -b 1 -kt \"images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fMh0RXvk-GS"
   },
   "source": [
    "### pt 모델과 tflite 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 53251,
     "status": "ok",
     "timestamp": 1751619141503,
     "user": {
      "displayName": "k im",
      "userId": "08581733427727695003"
     },
     "user_tz": -540
    },
    "id": "OVgotonkmkBW",
    "outputId": "968e3562-2ef6-415e-f734-8af6462a0920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "--- .pt 모델 성능 평가 ---\n",
      "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.2 ms, read: 27.7±14.5 MB/s, size: 47.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:27<00:00,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.953      0.826      0.922      0.814\n",
      "                helmet         37         69      0.953      0.826      0.922      0.814\n",
      "Speed: 6.5ms preprocess, 688.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/pt_validation\u001b[0m\n",
      "\n",
      "--- .tflite 모델 성능 평가 ---\n",
      "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
      "Loading /content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results/helmet_detection_run_with_augmentation/weights/best_saved_model/best_float16.tflite for TensorFlow Lite inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 25.9±6.7 MB/s, size: 51.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hackerton/safe/HardHatDetector/valid/labels.cache... 39 images, 2 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 39/39 [00:19<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         39         69      0.903      0.807      0.888      0.739\n",
      "                helmet         37         69      0.903      0.807      0.888      0.739\n",
      "Speed: 2.0ms preprocess, 485.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/tflite_validation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 훈련된 yolov11s pt 모델과 tflite 변환 모델 성능 비교\n",
    "\"\"\"\n",
    "# --- 1. 경로 및 모델 로드 ---\n",
    "project_name = \"/content/drive/MyDrive/hackerton/safe/HardHatDetector/yolo_results\"\n",
    "run_name = \"helmet_detection_run_with_augmentation\"\n",
    "CUSTOM_YAML_PATH = '/content/drive/MyDrive/hackerton/safe/HardHatDetector/custom_data.yaml'\n",
    "\n",
    "best_model_path = f\"{project_name}/{run_name}/weights/best.pt\"\n",
    "tflite_model_path = f\"{project_name}/{run_name}/weights/best_saved_model/best_float16.tflite\"\n",
    "\n",
    "# 모델 로드\n",
    "best_model = YOLO(best_model_path)\n",
    "tflite_model = YOLO(tflite_model_path) # YOLO 객체로 TFLite 모델 로드\n",
    "\n",
    "# --- 2. 각 모델 성능 평가 ---\n",
    "print(\"--- .pt 모델 성능 평가 ---\")\n",
    "metrics_pt = best_model.val(data=CUSTOM_YAML_PATH, imgsz=640, name='pt_validation')\n",
    "\n",
    "print(\"\\n--- .tflite 모델 성능 평가 ---\")\n",
    "metrics_tflite = tflite_model.val(data=CUSTOM_YAML_PATH, imgsz=640, name='tflite_validation')\n",
    "\n",
    "# --- 3. 시각화를 위한 데이터 준비 ---\n",
    "labels = ['mAP50-95', 'mAP50', 'Precision', 'Recall']\n",
    "\n",
    "# .pt 모델의 성능 지표 추출\n",
    "pt_scores = [\n",
    "    metrics_pt.box.map,    # mAP50-95\n",
    "    metrics_pt.box.map50,  # mAP50\n",
    "    metrics_pt.box.p[0],   # Precision (전체 클래스 평균)\n",
    "    metrics_pt.box.r[0]    # Recall (전체 클래스 평균)\n",
    "]\n",
    "\n",
    "# .tflite 모델의 성능 지표 추출\n",
    "tflite_scores = [\n",
    "    metrics_tflite.box.map,\n",
    "    metrics_tflite.box.map50,\n",
    "    metrics_tflite.box.p[0],\n",
    "    metrics_tflite.box.r[0]\n",
    "]\n",
    "\n",
    "# --- 4. 시각화 ---\n",
    "x = np.arange(len(labels))  # 라벨의 개수에 맞춰 x축 위치 생성\n",
    "width = 0.35  # 막대그래프 너비\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "rects1 = ax.bar(x - width/2, pt_scores, width, label='YOLOv8 .pt')\n",
    "rects2 = ax.bar(x + width/2, tflite_scores, width, label='YOLOv8 .tflite (FP16)')\n",
    "\n",
    "# 레이블, 제목, 눈금 설정\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('YOLOv8 Model Performance Comparison (.pt vs TFLite)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "ax.bar_label(rects1, padding=3, fmt='%.4f')\n",
    "ax.bar_label(rects2, padding=3, fmt='%.4f')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Oyvk-UuFjxIb"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
